{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Files\n"
      ],
      "metadata": {
        "id": "HO8mFSVIhDTi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_cif5F5ZQ-q",
        "outputId": "ae1a9c5c-9f68-495f-adc3-e65115957f4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.csv', 'test_images', 'train_images']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import os\n",
        "BASE_DIR = '/content/drive/MyDrive/data'\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train_images')\n",
        "TEST_DIR  = os.path.join(BASE_DIR, 'test_images')\n",
        "CSV_PATH  = os.path.join(BASE_DIR, 'train.csv')\n",
        "OUTPUT_SUB = os.path.join(BASE_DIR, 'submission.csv')\n",
        "os.listdir(BASE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing packages\n"
      ],
      "metadata": {
        "id": "lEU9htwThI4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kMx3HeEtZ3ln",
        "outputId": "a59133c0-de9e-41c4-b87f-88e74664a76d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n"
      ],
      "metadata": {
        "id": "-ckTDFziaTOT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading Data\n"
      ],
      "metadata": {
        "id": "3V1azDFshUU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH)\n",
        "n_null = df['ClassId'].isna().sum()\n",
        "print(f\"Rows with missing ClassId: {n_null}\")\n",
        "\n",
        "if n_null > 0:\n",
        "    print(\"Some images have no valid ClassId. Here's a sample of those ImageIds:\")\n",
        "    print(df.loc[df['ClassId'].isna(), 'ImageId'].unique()[:10])\n",
        "    df = df.dropna(subset=['ClassId'])\n",
        "    print(f\"After dropping nulls, rows = {len(df)}\")\n",
        "df['ClassId'] = df['ClassId'].astype(int)\n",
        "label_df = (\n",
        "    df\n",
        "    .groupby('ImageId')['ClassId']\n",
        "    .agg(lambda x: x.value_counts().idxmax())\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"Unique images:\", label_df['ImageId'].nunique())\n",
        "print(\"Rows in label_df:\", len(label_df))\n",
        "print(label_df['ClassId'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-nhwZlgbzMK",
        "outputId": "e1acf5b1-a2e4-4ca8-f06f-e9eb5743c1b0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with missing ClassId: 1\n",
            "Some images have no valid ClassId. Here's a sample of those ImageIds:\n",
            "['2 367677 34 367793 32 367933 34 368049 32 368189 34 368305 32 368445 34 368561 32 368701 34 368817 32 368957 34 369073 32 369213 34 369329 32 369469 34 369585 32 369725 34 369841 32 369981 34 370097 32 370237 34 370353 32 370493 34 370609 32 370749 34 370865 32 371005 34 371121 32 371261 34 371377 32 371517 34 371632 33 371773 33 371888 33 372029 33 372144 33 372285 33 372400 33 372541 33 372656 33 372797 33 372912 33 373053 33 373168 33 373309 33 373424 33 373565 33 373680 33 373821 33 373936 33 374077 33 374192 33 374333 33 374448 33 374589 33 374704 33 374845 33 374960 33 375101 33 375216 33 375357 33 375472 33 375613 33 375728 33 375869 33 375984 33 376125 33 376240 33 376381 33 376496 33 376637 33 376752 33 376893 33 377008 33 377149 33 377264 33 377405 33 377520 33 377661 33 377776 33 377917 33 378032 33 378173 33 378288 33 378429 33 378544 33 378685 33 378800 33 378941 33 379056 33 379197 33 379312 33 379453 33 379568 33 379709 33 379824 33 379965 33 380080 33 380221 33 380336 33 380477 33 380592 33 380733 33 380848 33 380989 33 381104 33 381245 33 381360 33 381501 33 381616 33 381757 33 381872 33 382013 33 382128 33 382269 33 382384 33 382525 33 382640 33 382781 33 382896 33 383037 33 383152 33 383294 32 383408 33 383550 32 383664 33 383806 32 383920 33 384062 32 384176 33 384318 32 384432 33 384574 32 384688 33 384830 32 384944 33 385086 32 385200 33 385342 32 385456 33 385598 32 385712 33 385854 32 385968 33 386110 32 386224 33 386366 32 386480 33 386622 31 386736 33 386878 31 386992 33 387134 31 387248 33 387390 31 387504 33 387646 31 387760 33 387902 31 388016 33 388158 31 388272 32 388414 31 388528 32 388670 31 388784 32 388926 31 389040 32 389182 31 389296 32 389438 31 389552 32 389694 31 389808 32 389950 31 390064 32 390206 31 390320 32 390462 31 390576 32 390718 31 390832 32 390974 31 391088 32 391230 31 391344 32 391486 31 391600 32 391742 31 391856 32 391998 31 392113 31 392254 31 392369 31 392510 31 392625 31 392766 31 392881 31 393022 31 393137 31 393278 31 393393 31 393534 31 393649 31 393790 31 393905 31 394046 31 394161 31 394302 31 394417 31 394558 31 394673 31 394814 31 394929 31 395070 31 395185 31 395326 31 395441 31 395582 31 395697 31 395838 31 395953 31 396094 31 396209 31 396350 31 396465 31 396606 31 396721 31 396862 31 396977 31 397118 31 397233 31 397374 31 397489 31 397630 31 397745 31 397886 31 398001 31 398142 31 398257 31 398398 31 398513 31 398654 31 398769 31 398910 31 399025 31 399166 31 399281 31 399422 31 399537 31 399678 31 399793 31 399934 31 400049 31 400190 31 400305 31 400447 30 400561 31 400703 30 400817 31 400959 30 401073 31 401215 30 401329 31 401471 29 401585 31 401727 29 401841 31 401983 29 402097 31 402239 29 402353 31 402495 29 402609 31 402751 29 402865 31 403007 29 403122 30 403263 29 403378 30 403519 29 403634 30 403775 29 403890 30 404031 29 404146 30 404287 29 404402 30 404543 29 404658 30 404799 29 404914 30 405055 29 405170 30 405311 29 405426 30 405567 29 405682 30 405823 29 405938 30 406079 29 406194 30 406335 29 406450 30 406591 29 406706 30 406847 29 406962 30 407103 29 407218 30 407359 29 407474 30 407615 29 407730 30 407871 29 407986 30 408127 29 408242 30 408383 29 408498 30 408639 29 408895 14']\n",
            "After dropping nulls, rows = 7095\n",
            "Unique images: 6666\n",
            "Rows in label_df: 6666\n",
            "ClassId\n",
            "3    5043\n",
            "1     897\n",
            "4     516\n",
            "2     210\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train / Validation Split"
      ],
      "metadata": {
        "id": "kEtAclUNgSSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(\n",
        "    label_df,\n",
        "    test_size=0.2,\n",
        "    stratify=label_df['ClassId'],\n",
        "    random_state=42\n",
        ")\n",
        "print(f\"→ Train: {len(train_df)} images, Val: {len(val_df)} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W-HrAYQc8BD",
        "outputId": "58e013ed-dd5f-47eb-fa84-4a474f881517"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Train: 5332 images, Val: 1334 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset & DataLoader"
      ],
      "metadata": {
        "id": "f41WZL-CgJUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/data'\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train_images')\n",
        "TEST_DIR  = os.path.join(BASE_DIR, 'test_images')\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class SteelDefectDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.df.loc[idx, 'ImageId']\n",
        "        label  = self.df.loc[idx, 'ClassId'] - 1\n",
        "        img_path = os.path.join(self.img_dir, img_id)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "train_ds = SteelDefectDataset(train_df, TRAIN_DIR, train_transforms)\n",
        "val_ds   = SteelDefectDataset(val_df,   TRAIN_DIR, val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "M4Wpps7-dRmt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Creation"
      ],
      "metadata": {
        "id": "KOUowJtEhh-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 4)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKGt0-ydVkr",
        "outputId": "021e1a27-abf4-4b00-9cc3-1755d7634692"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Loop"
      ],
      "metadata": {
        "id": "xtRj64s5hyFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_files = os.listdir(TRAIN_DIR)\n",
        "file_map = { os.path.splitext(fname)[0]: fname\n",
        "             for fname in all_files }\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class SteelDefectDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, file_map, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.file_map = file_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.df.loc[idx, 'ImageId']\n",
        "        fname = self.file_map.get(img_id)\n",
        "        if fname is None:\n",
        "            raise FileNotFoundError(f\"No file for ID {img_id} in {self.img_dir}\")\n",
        "        img_path = os.path.join(self.img_dir, fname)\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = self.df.loc[idx, 'ClassId'] - 1\n",
        "        return img, label\n",
        "\n",
        "train_ds = SteelDefectDataset(train_df, TRAIN_DIR, file_map, train_transforms)\n",
        "val_ds   = SteelDefectDataset(  val_df, TRAIN_DIR, file_map, val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "t4ocNa1edadi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = os.path.join(BASE_DIR, \"best_resnet18.pth\")\n",
        "\n",
        "# inside your training loop, when you get a new best:\n",
        "torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
        "print(f\"  ↳ Saved new best model to {CHECKPOINT_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16tNhVEZeRYY",
        "outputId": "7d398b42-6fe6-45e7-ccb2-ad70b2507002"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↳ Saved new best model to /content/drive/MyDrive/data/best_resnet18.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference & Submission"
      ],
      "metadata": {
        "id": "cLolMykzhnsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "BASE_DIR        = '/content/drive/MyDrive/data'\n",
        "TEST_DIR        = os.path.join(BASE_DIR, 'test_images')\n",
        "CHECKPOINT_PATH = os.path.join(BASE_DIR, 'best_resnet18.pth')\n",
        "OUT_CSV         = os.path.join(BASE_DIR, 'submission.csv')\n",
        "test_files = os.listdir(TEST_DIR)\n",
        "test_file_map = { os.path.splitext(f)[0]: f for f in test_files }\n",
        "print(f\"Found {len(test_files)} files in TEST_DIR, mapping covers {len(test_file_map)} IDs\")\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_dir, bare_ids, file_map, transform=None):\n",
        "        self.img_dir    = img_dir\n",
        "        self.bare_ids   = bare_ids\n",
        "        self.file_map   = file_map\n",
        "        self.transform  = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.bare_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        bare_id = self.bare_ids[idx]\n",
        "        fname   = self.file_map.get(bare_id, None)\n",
        "        if fname is None:\n",
        "            raise FileNotFoundError(f\"No file for ID {bare_id} in {self.img_dir}\")\n",
        "        img_path = os.path.join(self.img_dir, fname)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, bare_id\n",
        "\n",
        "bare_test_ids = sorted(test_file_map.keys())\n",
        "test_ds       = TestDataset(TEST_DIR, bare_test_ids, test_file_map, val_transforms)\n",
        "test_loader   = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "assert os.path.exists(CHECKPOINT_PATH), f\"Checkpoint not found at {CHECKPOINT_PATH}\"\n",
        "model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
        "model.eval()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for imgs, ids in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = model(imgs)\n",
        "        classes = outputs.argmax(dim=1).cpu().numpy() + 1\n",
        "        for bare_id, cls in zip(ids, classes):\n",
        "            preds.append((bare_id, cls))\n",
        "sub_df = pd.DataFrame(preds, columns=['ImageId','ClassId'])\n",
        "sub_df.to_csv(OUT_CSV, index=False)\n",
        "print(f\"✅ Saved submission to {OUT_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RJXc-hfepfy",
        "outputId": "978fc6a0-9505-4583-8be9-8cfa7474b7d8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 files in TEST_DIR, mapping covers 10 IDs\n",
            "✅ Saved submission to /content/drive/MyDrive/data/submission.csv\n"
          ]
        }
      ]
    }
  ]
}